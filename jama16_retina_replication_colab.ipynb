{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jama16-retina-replication-colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pichetzh/jama16-retina-replication/blob/master/jama16_retina_replication_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "7Z2jcRKwUHqV"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook provides recipes for loading and saving data from external sources."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Xyazv22SBq2-"
      },
      "cell_type": "markdown",
      "source": [
        "# System Configuration"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "sfIolbbCBv3B",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!echo \"Hard drive info\\n===========================\"\n",
        "!df -H /\n",
        "!echo \"\\nRAM info\\n===========================\"\n",
        "!free -h\n",
        "!echo \"\\nVM User info\\n===========================\"\n",
        "!whoami\n",
        "\n",
        "import tensorflow as tf\n",
        "# This should print out an output like \"/device:GPU:0\". If you get an empty \n",
        "# string, verify you are on a GPU runtime. \n",
        "# Goto Runtime menu -> Change runtime type -> Select GPU in the hardware accelerator spinner\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "AnaYefuhtRj2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!lsb_release -a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TPwWqYznrU1X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Clone GIT repository\n"
      ]
    },
    {
      "metadata": {
        "id": "Rp6o1D6prZHz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# initialize only once\n",
        "GIT_USERNAME = \"pichetzh\" \n",
        "GIT_TOKEN = \"68594bcc127e64863a341dbdcbd50ef55c8774e4\" \n",
        "GIT_REPOSITORY = \"jama16-retina-replication\" # by forking\n",
        "GIT_PATH = \"/content/_github\" # this folder must be empty at initialization\n",
        "!git clone --recursive https://{GIT_TOKEN}@github.com/{GIT_USERNAME}/{GIT_REPOSITORY}.git \"{GIT_PATH}\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hWevxQJWrbY3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load the create_tfrecords repository. \n",
        "# This tool will convert the data sets into TFRecord files\n",
        "%%bash\n",
        "cd /content/_github\n",
        "git submodule update --init --recursive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Sfg8H6pewu63"
      },
      "cell_type": "markdown",
      "source": [
        "# Upload Data From G Drive"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "p5XWTsZnbExW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "\n",
        "ROOT = \"/content/_gdrive\"\n",
        "drive.mount(ROOT, force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_hlovPKHyWPB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd /content/_data/messidor\n",
        "rm -rf *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qJ093WZjKMa-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# extract data file\n",
        "import os\n",
        "from os.path import join\n",
        "import zipfile\n",
        "\n",
        "COLAB_PATH = '/content/_gdrive/My Drive/_colab'\n",
        "path_to_zip_file = join(COLAB_PATH, 'data', \n",
        "                        'diabetic_retinopathy', 'jama16')\n",
        "\n",
        "!mkdir -p /content/_data\n",
        "directory_to_extract_to = '/content/_data'\n",
        "for f in os.listdir(path_to_zip_file):\n",
        "  zip_ref = zipfile.ZipFile(join(path_to_zip_file, f), 'r')\n",
        "  zip_ref.extractall(directory_to_extract_to)\n",
        "  zip_ref.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HnJeB2hMI6oR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# extract master file\n",
        "\n",
        "import os\n",
        "from os.path import join\n",
        "import zipfile\n",
        "\n",
        "COLAB_PATH = '/content/_gdrive/My Drive/_colab'\n",
        "master_folder = 'master-jama16-retina-replication'\n",
        "MASTER_PATH = join('/content', master_folder)\n",
        "\n",
        "path_to_zip_file = join(COLAB_PATH, 'projects', \n",
        "                        'diabetic-retinopathy', master_folder+'.zip')  \n",
        "directory_to_extract_to = '/content'\n",
        "zip_ref = zipfile.ZipFile(path_to_zip_file, 'r')\n",
        "zip_ref.extractall(directory_to_extract_to)\n",
        "zip_ref.close()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7VHVZHkbJANO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# extract data file\n",
        "path_to_zip_file = '/content/gdrive/My Drive/Colab_Experimental/data/diabetic_retinopathy/data.zip'  \n",
        "directory_to_extract_to = '/content'\n",
        "zip_ref = zipfile.ZipFile(path_to_zip_file, 'r')\n",
        "zip_ref.extractall(directory_to_extract_to)\n",
        "zip_ref.close()"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2ZKFPg_BrdLx",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!echo 'debconf debconf/frontend select Noninteractive' | debconf-set-selections\n",
        "!sudo apt-get -qq install tree\n",
        "!sudo apt-get -qq install caffeine\n",
        "!sudo apt-get -qq install nano\n",
        "!echo\n",
        "!tree --filelimit 30 -x -d -C -L 4 --dirsfirst $MASTER_PATH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "FH3-oYy7uJbq"
      },
      "cell_type": "markdown",
      "source": [
        "# Check packages"
      ]
    },
    {
      "metadata": {
        "id": "skdCHfFpy5n7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip -qq install watermark yagmail\n",
        "pip -qq install -U -q PyDrive\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3UmCbCFttYb6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%reload_ext watermark\n",
        "%watermark -p tensorflow,numpy,python,pillow,PILLOW,h5py,xlrd,matplotlib,p7zip-full,unzip,yagmail -m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QOlM2OuJrVqy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "grab_version () {\n",
        "  echo $1 $(dpkg -s $1 | grep -i version:)\n",
        "}\n",
        "\n",
        "grab_version python\n",
        "grab_version python3 \n",
        "grab_version python3-pil  # substitute for pillow\n",
        "#grab_version python-xlrd  # substitute for pillow\n",
        "#grab_version xlrd \n",
        "grab_version p7zip-full\n",
        "grab_version unzip \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yM2v5z6DU0Am",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Fetching GIT repository\n",
        "GIT_USERNAME = \"pichetzh\"\n",
        "GIT_TOKEN = \"68594bcc127e64863a341dbdcbd50ef55c8774e4\"\n",
        "GIT_REPOSITORY = \"jama16-retina-replication-colab\"\n",
        "\n",
        "GIT_PATH = join(MASTER_PATH, 'git_hub')\n",
        "!git clone https://{GIT_TOKEN}@github.com/{GIT_USERNAME}/{GIT_REPOSITORY}.git \"{GIT_PATH}\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j3aUSR5D-9ec",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd /content\n",
        "cp /content/train.py /content/master-jama16-retina-replication/train.py\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "us3WTJX6FpKv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "mkdir -p /content/_github/_addon\n",
        "cd /content\n",
        "#mv roc.ipynb /content/_github/_addon\n",
        "#mv /content/Google_Colaboratory_backup.py /content/_github/_addon\n",
        "mv send_yagmail.py /content/_github/_addon\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "QmbtIq9GJx1k"
      },
      "cell_type": "markdown",
      "source": [
        "# train.py"
      ]
    },
    {
      "metadata": {
        "id": "Y7Zbre478iNv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Various loading and saving constants.\n",
        "default_train_dir = \"./data/eyepacs/bin2/train\"\n",
        "default_val_dir = \"./data/eyepacs/bin2/validation\"\n",
        "default_save_model_path = \"./tmp/model\"\n",
        "default_save_summaries_dir = \"./tmp/logs\"\n",
        "default_save_operating_thresholds_path = \"./tmp/op_pts.csv\"\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WwrMpm0Y6Pgo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd /content/_github\n",
        "python train.py -h\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G_FCqFvV-pVk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TRAIN_DIR = '/content/_data/messidor/bin2'\n",
        "os.chdir('/content/_github')\n",
        "! python train.py -t {TRAIN_DIR}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EVL-mjD5-Pje",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TRAIN_DIR = '/content/_data/messidor/bin2'\n",
        "\n",
        "GIT_PATH = \"/content/_github\" # this folder must be empty at initialization\n",
        "!git clone --recursive https://{GIT_TOKEN}@github.com/{GIT_USERNAME}/{GIT_REPOSITORY}.git \"{GIT_PATH}\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZG2qUjtF-z3D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TRAIN_DIR = '/content/_data/messidor/bin2'\n",
        "! cd /content/_github\n",
        "! python train.py -t {TRAIN_DIR}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bIOVAoxg9pru",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd /content/_github\n",
        "python train.py -t {$TRAIN_DIR}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "GnRbTBz0Od6x",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "os.chdir(MASTER_PATH)\n",
        "start = time.time()\n",
        "! python train.py -t '/content/data/eyepacs-52478/bin2/train' \\\n",
        "  -v '/content/data/eyepacs-52478/bin2/validation'\n",
        "end = time.time()\n",
        "print(\"time elapsed: {} hours\".format((end - start)/3600))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fXv-4xGC6QN-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# define execution directories\n",
        "import os\n",
        "from os.path import join\n",
        "SAMPLE_PATH = '/content/data/eyepacs/bin2'\n",
        "OUTPUT_PATH = '/content/jama16-retina-replication-master/tmp'\n",
        "train_dir = join(SAMPLE_PATH,\"train\")\n",
        "val_dir = join(SAMPLE_PATH,\"validation\")\n",
        "save_model_path = join(OUTPUT_PATH,\"model\")\n",
        "save_summaries_dir = join(OUTPUT_PATH,\"logs\")\n",
        "save_operating_thresholds_path = join(OUTPUT_PATH,\"op_pts.csv\")\n",
        "os.chdir('/content/jama16-retina-replication-master')\n",
        "\n",
        "\n",
        "#!python train.py\n",
        "!echo -t $train_dir -v $val_dir -sm $save_model_path \\\n",
        "  -ss $save_summaries_dir -so $save_operating_thresholds_path\n",
        "  \n",
        "import time\n",
        "start = time.time()\n",
        "! python train.py -t $train_dir -v $val_dir -sm $save_model_path \\\n",
        "  -ss $save_summaries_dir -so $save_operating_thresholds_path\n",
        "end = time.time()\n",
        "print(\"time elapsed: {} hours\".format((end - start)/3600))"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "nAykILcDt28I",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# send email notification\n",
        "# pip install yagmail\n",
        "python send_yagmail.py\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0gU4TBtEyM3D",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "tree --filelimit 30 -C -L 4 --dirsfirst '/content/jama16-retina-replication-master/tmp'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "2eLLLZ3t0bS6"
      },
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ajxITz0x_vz6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# evaluatioin\n",
        "# evaluate on Kaggle_ EyePACS test set, run `$ python evaluate.py -e`. \n",
        "# evaluate on Messidor-Original, run it with the `-m` flag. \n",
        "# evaluate on Messidor-2, use the `-m2` flag\n",
        "#os.chdir('/content/jama16-retina-replication-master')\n",
        "os.chdir(MASTER_PATH)\n",
        "OUTPUT_PATH = '/content/jama16-retina-replication-master/tmp'\n",
        "save_operating_thresholds_path = join(OUTPUT_PATH,\"test_op_pts_eyepacs.csv\")\n",
        "!python evaluate.py -e -so $save_operating_thresholds_path\n",
        "!echo\n",
        "save_operating_thresholds_path = join(OUTPUT_PATH,\"test_op_pts_messidor.csv\")\n",
        "!python evaluate.py -m -so $save_operating_thresholds_path\n",
        "!echo\n",
        "save_operating_thresholds_path = join(OUTPUT_PATH,\"test_op_pts_messidor2.csv\")\n",
        "!python evaluate.py -m2 -so $save_operating_thresholds_path\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "cY-1mXUIvkik"
      },
      "cell_type": "markdown",
      "source": [
        "# Store tmp.zip in google drive"
      ]
    },
    {
      "metadata": {
        "id": "si75dQZGWQ_c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from pytz import timezone  \n",
        "def date_time_string(tz = timezone('Asia/Bangkok')):\n",
        "  tz_time = datetime.now(tz)\n",
        "  return tz_time.strftime('%Y-%m-%d_%H-%M-%S')\n",
        "\n",
        "# zip tmp folder as  zip_name (= tmp + timestamp + .zip)\n",
        "zip_name = 'tmp-' +date_time_string() + '.zip'\n",
        "os.chdir(MASTER_PATH)\n",
        "! zip -r $zip_name tmp\n",
        "# upload tmp.zip to google drive\n",
        "dest = '/content/_gdrive/\"My Drive\"/_colab/tmp/'\n",
        "!cp -a $zip_name $dest\n",
        "\n",
        "# download to local drive (MacbookPro)\n",
        "from google.colab import files\n",
        "files.download(zip_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MvPNuiS-acMQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# not used for file transfer"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "EPbkBEZarJ10"
      },
      "cell_type": "markdown",
      "source": [
        "# Setup for later Download to google drive\n",
        "\n",
        "#prepare for a backup of tmp/ folder in gdrive via a script in authenticate_pydrive.py\n",
        "import os\n",
        "from os.path import join\n",
        "#MASTER_PATH = '/content/jama16-retina-replication-master'\n",
        "os.chdir(MASTER_PATH)\n",
        "import Google_Colaboratory_backup as gcb\n",
        "gdrive_backup = gcb.authenticate_pydrive()\n",
        "#gcb.backup_pydrive()\n",
        "\n",
        "\n",
        "Install the PyDrive wrapper & import libraries.\n",
        "This only needs to be done once in a notebook.\n",
        "!pip install -U -q PyDrive from pydrive.auth import GoogleAuth from pydrive.drive import GoogleDrive from google.colab import auth from oauth2client.client import GoogleCredentials\n",
        "\n",
        "Authenticate and create the PyDrive client.\n",
        "This only needs to be done once in a notebook.\n",
        "cd into master_dir to store adc.json there\n",
        "we will transfer file from that dir (where adc.json resides)\n",
        "\n",
        "import os from os.path import join os.chdir(MASTER_PATH) auth.authenticate_user() gauth = GoogleAuth() gauth.credentials = GoogleCredentials.get_application_default() drive = GoogleDrive(gauth)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "H121jTKS0FZz",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Zip tmp as tmp.zip\n",
        "os.chdir(MASTER_PATH)\n",
        "! zip -r tmp.zip tmp\n",
        "\n",
        "# Upload tmp to google gdrive_backup.\n",
        "uploaded = gdrive_backup.CreateFile({'title': 'tmp.zip'})\n",
        "uploaded.SetContentFile('/content/jama16-retina-replication-master/tmp.zip')\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cZeNoqD_ak_r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5ve4iQAeX950",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# download to local drive (MacbookPro)\n",
        "from google.colab import files\n",
        "files.download(\"/content/jama16-retina-replication-master/tmp.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "crMglKekRdLQ"
      },
      "cell_type": "markdown",
      "source": [
        "# diagnose train.py"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "X63uxw4rNbFw",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "import argparse\n",
        "import csv\n",
        "from glob import glob\n",
        "import lib\n",
        "import lib.metrics\n",
        "import lib.dataset\n",
        "import lib.evaluation\n",
        "from lib.preprocess import rescale_min_1_to_1, rescale_0_to_1\n",
        "\n",
        "print(f\"Numpy version: {np.__version__}\")\n",
        "print(f\"Tensorflow version: {tf.__version__}\")\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "random.seed(432)\n",
        "\n",
        "\n",
        "# Various constants.\n",
        "num_channels = 3\n",
        "num_workers = 8\n",
        "normalization_fn = rescale_min_1_to_1\n",
        "\n",
        "# Hyper-parameters for training.\n",
        "learning_rate = 1e-3\n",
        "decay = 4e-5\n",
        "train_batch_size = 32\n",
        "\n",
        "# Hyper-parameters for validation.\n",
        "num_epochs = 200\n",
        "wait_epochs = 10\n",
        "min_delta_auc = 0.01\n",
        "val_batch_size = 32\n",
        "num_thresholds = 200\n",
        "kepsilon = 1e-7\n",
        "\n",
        "# Define thresholds.\n",
        "thresholds = lib.metrics.generate_thresholds(num_thresholds, kepsilon) + [0.5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KxeGOh7KN54M",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.test.is_gpu_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "N9YQ4FM1Nv_w",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Buffer size for image shuffling.\n",
        "shuffle_buffer_size = 2048\n",
        "prefetch_buffer_size = 2 * train_batch_size\n",
        "\n",
        "# Set image datas format to channels first if GPU is available.\n",
        "if tf.test.is_gpu_available():\n",
        "    print(\"Found GPU! Using channels first as default image data format.\")\n",
        "    image_data_format = 'channels_first'\n",
        "else:\n",
        "    image_data_format = 'channels_last'\n",
        "\n",
        "# Set up a session and bind it to Keras.\n",
        "sess = tf.Session()\n",
        "tf.keras.backend.set_session(sess)\n",
        "tf.keras.backend.set_learning_phase(True)\n",
        "tf.keras.backend.set_image_data_format(image_data_format)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JDxtGlEBx9HS",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initialize each data set.\n",
        "train_dataset = lib.dataset.initialize_dataset(\n",
        "    train_dir, train_batch_size,\n",
        "    num_workers=num_workers, prefetch_buffer_size=prefetch_buffer_size,\n",
        "    shuffle_buffer_size=shuffle_buffer_size,\n",
        "    image_data_format=image_data_format, num_channels=num_channels,\n",
        "    normalization_fn=normalization_fn)\n",
        "\n",
        "val_dataset = lib.dataset.initialize_dataset(\n",
        "    val_dir, val_batch_size,\n",
        "    num_workers=num_workers, prefetch_buffer_size=prefetch_buffer_size,\n",
        "    shuffle_buffer_size=shuffle_buffer_size,\n",
        "    image_data_format=image_data_format, num_channels=num_channels,\n",
        "    normalization_fn=normalization_fn)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "vKUOgwlxQTcX",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Create initializable iterators.\n",
        "iterator = tf.data.Iterator.from_structure(\n",
        "    train_dataset.output_types, train_dataset.output_shapes)\n",
        "\n",
        "images, labels = iterator.get_next()\n",
        "x = tf.placeholder_with_default(images, images.shape, name='x')\n",
        "y = tf.placeholder_with_default(labels, labels.shape, name='y')\n",
        "\n",
        "train_init_op = iterator.make_initializer(train_dataset)\n",
        "val_init_op = iterator.make_initializer(val_dataset)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hYtHCsVhQWl0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Base model InceptionV3 without top and global average pooling.\n",
        "base_model = tf.keras.applications.InceptionV3(\n",
        "    include_top=False, weights='imagenet', pooling='avg', input_tensor=x)\n",
        "\n",
        "# Add dense layer with the same amount of neurons as labels.\n",
        "logits = tf.layers.dense(base_model.output, units=1)\n",
        "\n",
        "# Get the predictions with a sigmoid activation function.\n",
        "predictions = tf.sigmoid(logits, name='predictions')\n",
        "\n",
        "# Retrieve loss of network using cross entropy.\n",
        "mean_xentropy = tf.reduce_mean(\n",
        "    tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=logits))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Rrf5bfkuQdin",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define optimizer.\n",
        "global_step = tf.Variable(0, dtype=tf.int32)\n",
        "\n",
        "train_op = tf.train.RMSPropOptimizer(\n",
        "    learning_rate=learning_rate, decay=decay) \\\n",
        "        .minimize(loss=mean_xentropy, global_step=global_step)\n",
        "\n",
        "# Metrics for finding best validation set.\n",
        "tp, update_tp, reset_tp = lib.metrics.create_reset_metric(\n",
        "    tf.metrics.true_positives_at_thresholds, scope='tp',\n",
        "    labels=y, predictions=predictions, thresholds=thresholds)\n",
        "\n",
        "fp, update_fp, reset_fp = lib.metrics.create_reset_metric(\n",
        "    tf.metrics.false_positives_at_thresholds, scope='fp',\n",
        "    labels=y, predictions=predictions, thresholds=thresholds)\n",
        "\n",
        "fn, update_fn, reset_fn = lib.metrics.create_reset_metric(\n",
        "    tf.metrics.false_negatives_at_thresholds, scope='fn',\n",
        "    labels=y, predictions=predictions, thresholds=thresholds)\n",
        "\n",
        "tn, update_tn, reset_tn = lib.metrics.create_reset_metric(\n",
        "    tf.metrics.true_negatives_at_thresholds, scope='tn',\n",
        "    labels=y, predictions=predictions, thresholds=thresholds)\n",
        "\n",
        "confusion_matrix = lib.metrics.confusion_matrix(\n",
        "    tp[-1], fp[-1], fn[-1], tn[-1], scope='confusion_matrix')\n",
        "\n",
        "brier, update_brier, reset_brier = lib.metrics.create_reset_metric(\n",
        "    tf.metrics.mean_squared_error, scope='brier',\n",
        "    labels=y, predictions=predictions)\n",
        "\n",
        "auc, update_auc, reset_auc = lib.metrics.create_reset_metric(\n",
        "    tf.metrics.auc, scope='auc', labels=y, predictions=predictions)\n",
        "tf.summary.scalar('auc', auc)\n",
        "\n",
        "specificities = tf.div(tn, tn + fp + kepsilon)\n",
        "sensitivities = tf.div(tp, tp + fn + kepsilon)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UlzRRkteQmeI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Merge all the summaries and write them out.\n",
        "summaries_op = tf.summary.merge_all()\n",
        "train_writer = tf.summary.FileWriter(save_summaries_dir + \"/train\")\n",
        "test_writer = tf.summary.FileWriter(save_summaries_dir + \"/test\")\n",
        "\n",
        "def print_training_status(epoch, num_epochs, batch_num, xent, i_step=None):\n",
        "    def length(x): return len(str(x))\n",
        "\n",
        "    m = []\n",
        "    m.append(\n",
        "        f\"Epoch: {{0:>{length(num_epochs)}}}/{{1:>{length(num_epochs)}}}\"\n",
        "        .format(epoch, num_epochs))\n",
        "    m.append(f\"Batch: {batch_num:>4}, Xent: {xent:6.4}\")\n",
        "\n",
        "    if i_step is not None:\n",
        "        m.append(f\"Step: {i_step:>10}\")\n",
        "\n",
        "    print(\", \".join(m), end=\"\\r\")\n",
        "\n",
        "\n",
        "# Add ops for saving and restoring all variables.\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "# Initialize variables.\n",
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(tf.local_variables_initializer())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WCHFJkxt5S0n",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Train for the specified amount of epochs.\n",
        "# Can be stopped early if peak of validation auc (Area under curve)\n",
        "#  is reached.\n",
        "latest_peak_auc = 0\n",
        "waited_epochs = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Start training.\n",
        "    tf.keras.backend.set_learning_phase(True)\n",
        "    sess.run(train_init_op)\n",
        "    batch_num = 0\n",
        "\n",
        "    # Track brier score for an indication on convergance.\n",
        "    sess.run(reset_brier)\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            # Optimize cross entropy.\n",
        "            i_global, batch_xent, *_ = sess.run(\n",
        "                [global_step, mean_xentropy, train_op, update_brier])\n",
        "\n",
        "            # Print a nice training status.\n",
        "            print_training_status(\n",
        "                epoch, num_epochs, batch_num, batch_xent, i_global)\n",
        "\n",
        "            # Report summaries.\n",
        "            print(batch_num)\n",
        "            batch_num += 1\n",
        "\n",
        "    except tf.errors.OutOfRangeError:\n",
        "        # Retrieve training brier score.\n",
        "        print('Retrieve training brier score')\n",
        "        train_brier = sess.run(brier)\n",
        "        print(\"\\nEnd of epoch {0}! (Brier: {1:8.6})\".format(epoch, train_brier))\n",
        "\n",
        "    # Perform validation.\n",
        "    val_auc = lib.evaluation.perform_test(\n",
        "        sess=sess, init_op=val_init_op,\n",
        "        summary_writer=train_writer, epoch=epoch)\n",
        "\n",
        "    if val_auc < latest_peak_auc + min_delta_auc:\n",
        "        # Stop early if peak of val auc has been reached.\n",
        "        # If it is lower than the previous auc value, wait up to `wait_epochs`\n",
        "        #  to see if it does not increase again.\n",
        "\n",
        "        if wait_epochs == waited_epochs:\n",
        "            print(\"Stopped early at epoch {0} with saved peak auc {1:10.8}\"\n",
        "                  .format(epoch+1, latest_peak_auc))\n",
        "            break\n",
        "\n",
        "        waited_epochs += 1\n",
        "    else:\n",
        "        latest_peak_auc = val_auc\n",
        "        print(f\"New peak auc reached: {val_auc:10.8}\")\n",
        "\n",
        "        # Save the model weights.\n",
        "        saver.save(sess, save_model_path)\n",
        "\n",
        "        # Reset waited epochs.\n",
        "        waited_epochs = 0\n",
        "\n",
        "# Load the saved best meta graph and restore variables from that checkpoint.\n",
        "saver = tf.train.import_meta_graph(\"{}.meta\".format(save_model_path))\n",
        "saver.restore(sess, save_model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "EQRfqu8EQN4-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Get predictions of all data of our training set.\n",
        "tf.keras.backend.set_learning_phase(False)\n",
        "sess.run([train_init_op, reset_tp, reset_fp, reset_fn, reset_tn])\n",
        "\n",
        "try:\n",
        "    while True:\n",
        "        # Update all confusion metrics for each batch.\n",
        "        sess.run([update_tp, update_fp, update_fn, update_tn])\n",
        "\n",
        "except tf.errors.OutOfRangeError:\n",
        "    pass\n",
        "\n",
        "# Write sensitivities and specificities to file.\n",
        "with open(save_operating_thresholds_path, 'w') as csvfile:\n",
        "    writer = csv.writer(csvfile, delimiter=' ')\n",
        "    writer.writerow(['threshold', 'specificity', 'sensitivity'])\n",
        "\n",
        "    train_specificities, train_sensitivities = \\\n",
        "        sess.run([specificities, sensitivities])\n",
        "\n",
        "    for idx in range(num_thresholds):\n",
        "        writer.writerow([\n",
        "            \"{:0.4f}\".format(x) for x in [\n",
        "                thresholds[idx], train_specificities[idx],\n",
        "                train_sensitivities[idx]]])\n",
        "\n",
        "# Close the session.\n",
        "sess.close()\n",
        "sys.exit(0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "GJeA3JoOQo7V",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#https://stackoverflow.com/questions/45100483/batch-request-with-google-cloud-storage-python-client\n",
        "from google.cloud import storage\n",
        "\n",
        "storage_client = storage.Client()\n",
        "bucket = storage_client.get_bucket('my_bucket_name')\n",
        "# Accumulate the iterated results in a list prior to issuing\n",
        "# batch within the context manager\n",
        "blobs_to_delete = [blob for blob in bucket.list_blobs(prefix=\"my/prefix/here\")]\n",
        "\n",
        "# Use the batch context manager to delete all the blobs    \n",
        "with storage_client.batch():\n",
        "    for blob in blobs_to_delete:\n",
        "        blob.delete()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "im8idv89RKlj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#https://stackoverflow.com/questions/45100483/batch-request-with-google-cloud-storage-python-client\n",
        "from google.cloud import storage\n",
        "\n",
        "storage_client = storage.Client()\n",
        "bucket = storage_client.get_bucket('my_bucket_name')\n",
        "# Accumulate the iterated results in a list prior to issuing\n",
        "# batch within the context manager\n",
        "blobs_to_delete = [blob for blob in bucket.list_blobs(prefix=\"my/prefix/here\")]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TRc797m4_Yj-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}